{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"STMTools","text":"<p>STMTools (Space-Time Matrix Tools) is an Xarray extension for Space-Time Matrix operations (Bruna et al., 2021; van Leijen et al., 2021). It provides tools to read, write, enrich and manipulate a Space-Time Matrix (STM).</p> <p>An STM is a dataset containing data with a space (point, location) and time (epoch) component, as well as contextual data. STMTools utilizes Xarray\u2019s multi-dimensional labeling feature, and Zarr's chunk storage feature, to efficiently read and write large Space-Time matrices.</p> <p>The contextual data enrichment functionality is implemented with Dask. Therefore it can be performed in a paralleled style on High Performance Computing (HPC) systems.</p> <p>At this stage, STMTools specifically focuses on the implementation for radar interferometry measurements, e.g. Point Scatterers, Distributed Scatterers, etc, with the possibility to be extended to other measurements with space and time attributes.</p>"},{"location":"#references","title":"References","text":"<p>[1] Bruna, M. F. D., van Leijen, F. J., &amp; Hanssen, R. F. (2021). A Generic Storage Method for Coherent Scatterers and Their Contextual Attributes. In 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS: Proceedings (pp. 1970-1973). [9553453] (International Geoscience and Remote Sensing Symposium (IGARSS); Vol. 2021-July). IEEE . https://doi.org/10.1109/IGARSS47720.2021.9553453</p> <p>[2] van Leijen, F. J., van der Marel, H., &amp; Hanssen, R. F. (2021). Towards the Integrated Processing of Geodetic Data. In 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS: Proceedings (pp. 3995-3998). [9554887] IEEE . https://doi.org/10.1109/IGARSS47720.2021.9554887</p>"},{"location":"CHANGELOG/","title":"Change Log","text":"<p>All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning.</p> <p>[0.1.0] - 2023-11-19</p> <ul> <li> <p>Added</p> <p>The first version of the STMTools package. The following functionalities are implemented:</p> <ul> <li>Data loading function from csv files;</li> <li>Subset function based on thresholding and polygons;</li> <li>Enrichment function from polygons;</li> <li>Dimension regulating function;</li> <li>Metadata registration function;</li> <li>Relevant docs and tests.</li> </ul> </li> </ul>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":"<p>This code of conduct is adapted from the  Git Code of Conduct.</p>"},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Project maintainers are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at team-atlas@esciencecenter.nl.</p> <p>All complaints will be reviewed and investigated promptly and fairly.</p> <p>All Project maintainers are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4,  available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html</p>"},{"location":"CONTRIBUTING/","title":"STMTools Contributing Guidelines","text":"<p>We welcome any kind of contribution to our software, from a simple comment  or question to a full fledged pull request.  Please read and follow our Code of Conduct.</p> <p>A contribution can be one of the following cases:</p> <ul> <li>you have a question;</li> <li>you think you may have found a bug (including unexpected behavior);</li> <li>you want to make some kind of change to the code base (e.g. to fix a bug, to add a new feature, to update documentation).</li> </ul> <p>The sections below outline the steps in each case.</p>"},{"location":"CONTRIBUTING/#you-have-a-question","title":"You have a question","text":"<ul> <li>use the search functionality in GitHub issue to see if someone already filed the same issue;</li> <li>if your issue search did not yield any relevant results, create a new issue;</li> <li>add the \"question\" label; include other labels when relevant.</li> </ul>"},{"location":"CONTRIBUTING/#you-think-you-may-have-found-a-bug","title":"You think you may have found a bug","text":"<ul> <li>use the search functionality in GitHub issue to see if someone already filed the same issue;</li> <li>if your issue search did not yield any relevant results, create a new issue, making sure to provide enough information to the rest of the community to understand the cause and context of the problem. Depending on the issue, you may want to include:<ul> <li>the SHA hashcode of the commit that is causing your problem;</li> <li>some identifying information (name and version number) for dependencies you're using;</li> <li>information about the operating system;</li> </ul> </li> <li>add relevant labels to the newly created issue.</li> </ul>"},{"location":"CONTRIBUTING/#you-want-to-make-some-kind-of-change-to-the-code-base","title":"You want to make some kind of change to the code base","text":"<ul> <li>(important) announce your plan to the rest of the community before you start working. This announcement should be in the form of a (new) issue;</li> <li>(important) wait until some kind of consensus is reached about your idea being a good idea;</li> <li>if needed, fork the repository to your own Github profile and create your own feature branch off of the latest master commit. While working on your feature branch, make sure to stay up to date with the master branch by pulling in changes, possibly from the 'upstream' repository (follow the instructions from GitHub: instruction 1: configuring a remote for a fork and instruction 2: syncing a fork);</li> <li>make sure the existing tests still work by running, e.g. <code>pytest tests</code>;</li> <li>add your own tests (if necessary);</li> <li>update or expand the documentation;</li> <li>make sure the linting tests pass by running <code>ruff</code> in the project root directory: <code>ruff check .</code>;</li> <li>push your feature branch to (your fork of) the stmtools repository on GitHub;</li> <li>create the pull request, e.g. following the instructions: creating a pull request.</li> </ul> <p>In case you feel like you've made a valuable contribution, but you don't know how to write or run tests for it, or how to generate the documentation: don't let this discourage you from making the pull request; we can help you! Just go ahead and submit the pull request, but keep in mind that you might be asked to append additional commits to your pull request.</p> <p>In case you want to add documentation and you don't have mkdocs installed in your root environment, you can install it by calling <code>pip install -e .[docs]</code>. You can then test your documentation by calling <code>mkdocs serve</code>.</p>"},{"location":"operations/","title":"Operations on STM","text":"<p>STMTools supports various operations on an STM.</p>"},{"location":"operations/#enrich-an-stm","title":"Enrich an STM","text":"<p>Contextual data can be added to an STM by enrichment. At present, STMTools supports enriching an STM by static polygons.</p> <p>For example, if soil type data (<code>soil_map.gpkg</code>) is available together with an STM, one can first read <code>soil_map.gpkg</code> using the <code>GeoPandas</code> library as a <code>GeoDataFrame</code>, then add the soil type and corresponding type ID to the STM, using the <code>enrich_from_polygon</code> function.</p> <p><pre><code>import geopandas as gpd\npolygon = gpd.read_file('soil_map.gpkg')\nfields_to_query = ['soil_type', 'type_id']\nstmat_enriched = stmat.stm.enrich_from_polygon(polygon, fields_to_query)\n</code></pre> Two attributes from <code>soil_map.gpkg</code>: <code>soil_type</code> and <code>type_id</code>, will be added as data variables to the STM.</p> <p>In case of a large file <code>soil_map.gpkg</code>, one can directly pass the file path to <code>enrich_from_polygon</code> to trigger the chunked enrichment:</p> <pre><code>path_polygon = Path('soil_map.gpkg')\nfields_to_query = ['soil_type', 'type_id']\nstmat_enriched = stmat.stm.enrich_from_polygon(path_polygon, fields_to_query)\n</code></pre>"},{"location":"operations/#subset-an-stm","title":"Subset an STM","text":"<p>A subset of an STM can be obtained based on 1) thresholding on an attribute, or 2) intersection with a background polygon.</p>"},{"location":"operations/#subset-by-an-attribute","title":"Subset by an attribute","text":"<p>For example, select entries with <code>pnt_enscoh</code> higher than 0.7:</p> <pre><code>stmat_subset = stmat.stm.subset(method='threshold', var='pnt_enscoh', threshold='&gt;0.7')\n</code></pre> <p>This is equivalent to Xarray filtering:</p> <pre><code>mask = stmat['pnt_enscoh'] &gt; 0.7\nmask = mask.compute()\nstmat_subset = stmat.where(mask, drop=True)\n</code></pre>"},{"location":"operations/#subset-by-a-polygon","title":"Subset by a polygon","text":"<p>Select all entries inside the polygons in <code>example_polygon.shp</code>:</p> <pre><code>import geopandas as gpd\npolygon = gpd.read_file('example_polygon.shp')\nstm_demo.stm.subset(method='polygon', polygon=polygon)\n</code></pre> <p>Subset can also operate on the polygon file directly if the file is too big to load in the memory:</p> <pre><code>stmat_subset = stm_demo.stm.subset(method='polygon', polygon='example_polygon.gpkg')\n</code></pre>"},{"location":"operations/#regulate-the-dimensions-of-an-stm","title":"Regulate the dimensions of an STM","text":"<p>Use <code>regulate_dims</code> to add a missing <code>space</code> or <code>time</code> dimension.</p> <pre><code># An STM witout time dimension\nnspace = 10\nstm_only_space = xr.Dataset(data_vars=dict(data=(['space'], np.arange(nspace))))\n\nstm_only_space\n</code></pre> <pre><code>&lt;xarray.Dataset&gt;\nDimensions:  (space: 10)\nDimensions without coordinates: space\nData variables:\n    data     (space) int64 0 1 2 3 4 5 6 7 8 9\n</code></pre> <pre><code>stm_only_space.regulate_dims()\n</code></pre> <pre><code>&lt;xarray.Dataset&gt;\nDimensions:  (time: 1, space: 10)\nDimensions without coordinates: time, space\nData variables:\n    data     (space, time) int64 0 1 2 3 4 5 6 7 8 9\n</code></pre>"},{"location":"operations/#assign-metadata","title":"Assign metadata","text":"<p>Use <code>register_metadata</code> to assign metadata to an STM by a Python dictionary.</p> <pre><code>metadata_normal = dict(techniqueId='ID0001', datasetId='ID_datasetID', crs=4326)\nstmat_with_metadata = stmat.stm.register_metadata(metadata_normal)\n</code></pre>"},{"location":"order/","title":"Ordering an STM","text":"<p>STMTools supports (re)ordering the elements in an STM.</p>"},{"location":"order/#why-element-order-is-important","title":"Why element order is important","text":"<p>The data elements in an STM can be ordered according to a wide variety aspects, such as time, horizontal before vertical, or classification. The choice of order can have a significant impact on the performance of operations applied to the data.</p> <p>An important consideration is that operations often don't have to be applied to the complete dataset. An STM is always loaded per chunk and an operation may be able to ignore a chunk based on its metadata, such as its bounding box. It can be beneficial to group elements into chunks that will usually be processed or ignored together.</p> <p>Our operations often prefer elements to be ordered by spatial coherency. For example, to enrich or subset an STM, the element positions will have to be compared to polygons. Ideally, we only want to process elements that are near the query polygon.</p>"},{"location":"order/#how-are-elements-reordered","title":"How are elements reordered","text":"<p>When applying spatial ordering, we order the elements according to their Morton code. A Morton code is a single integer representation of a higher dimensional coordinate. The following image shows a few sequences of Morton codes as a polyline for a few small sets of 2D points.</p> <p></p> <p>The translation to Morton code can be direct when the point coordinates are integers, such as pixel coordinates. Floating point coordinates must be scaled and truncated to integer values first. The choice of scale factor determines the resolution of the Morton code.</p> <p>Note that for a detailed dataset, a close group of points could be assigned the same Morton code, depending on the choice of scale factor. These points will be grouped together after ordering, but their internal order will not be strictly determined. In other words, we cannot detemine beforehand what their order will be, but they will not be separated by points with a different Morton code.</p>"},{"location":"order/#ordering-existing-stmat","title":"Ordering existing stmat","text":"<p>Reordering an existing STM is very straightforward. If the coordinates are integer values, such as the pixel coordinates <code>X</code> and <code>Y</code>, the STM can be reordered as follows:</p> <pre><code>stmat_ordered = stmat_xy.stm.reorder(xlabel='X', ylabel='Y')\n</code></pre> <p>If the coordinates are floating point coordinates, such as longitude and latitude, you must choose a scale factor for each coordinate such that points that are at least a unit distance apart in either direction can be differentiated by their Morton code. For example, a scale factor of <code>1.1*10^5</code> on the latitude coordinate means that points that are at least 1 meter apart will be assigned a different Morton code.</p> <pre><code>stmat_ordered = stmat_lonlat.stm.reorder(xlabel='lon', ylabel='lat', xscale=1.5*(10**5), yscale=1.7*(10**5))\n</code></pre> <p>Reordering the STM is actually a two-step process: computing the Morton codes and sorting the STM. You can also apply these steps separately:</p> <pre><code>stmat_ordered = stmat_ar.stm.get_order(xlabel='azimuth', ylabel='range', xscale=15, yscale=17)\nstmat_ordered = stmat_ordered.sortby(stmat_ordered.order)\n</code></pre> <p>This process will cut the chunks into many small pieces and reorder those pieces. It does not combine them into bigger chunks. The <code>reorder</code> function above will also rechunk the data using the same chunk sizes as before reordering.</p>"},{"location":"order/#ordering-new-stmat","title":"Ordering new stmat","text":"<p>Reading and writing data to disk can cost a significant amount of time. It is usually beneficial not to overwrite existing data unless necessary. If you intend to apply spatial ordering to your STM, we advise doing so before writing your data to disk.</p> <p>The following example selects some points of a sarxarray, reorders then, and only then writes them to disk:</p> <pre><code>stmat = stack.slcstack.point_selection(threshold=0.25, method='amplitude_dispersion')\nstmat = stmat.stm.reorder(xlabel='azimuth', ylabel='range', xscale=15, yscale=17)\nstmat.to_zarr('stm.zarr')\n</code></pre>"},{"location":"order/#effect-on-processing-time","title":"Effect on processing time","text":"<p>The example notebooks contain an example of the effect on processing time of ordering the STM: Example Ordering notebook</p> <p>This notebook also shows when ordering may not yield significant benefits. As a rule of thumb, ordering is expected to be beneficial when the chunks are small relative to the size and spatial extent of the data. In this case, reordering can reduce the spatial extent of the chunks while keeping their size, i.e. number of elements, the same.</p>"},{"location":"setup/","title":"Installation","text":"<p>STMTools can be installed from PyPI:</p> <pre><code>pip install stmtools\n</code></pre> <p>or from the source:</p> <pre><code>git clone git@github.com:TUDelftGeodesy/stmtools.git\ncd stmtools\npip install .\n</code></pre> <p>Note that Python version <code>&gt;=3.10</code> is required for STMTools.</p>"},{"location":"setup/#tips","title":"Tips","text":"<p>We strongly recommend installing separately from your default Python environment. E.g. you can use environment manager e.g. mamba to create separate environment.</p>"},{"location":"stm_init/","title":"Initiate a Space-Time Matrix","text":"<p>We implemented STM in Python as an <code>Xarray.Dataset</code> object. An STM instance can be initiated as an <code>Xarray.Dataset</code> in different ways.</p> <p>STMTools provides a reader to perform lazy loading from a csv file. However, we recommend to store STM in <code>zarr</code> format, and directly load them as an Xarray object by <code>xarray.open_zarr</code>.</p>"},{"location":"stm_init/#manually-initiate-an-stm","title":"Manually initiate an STM","text":"<p>When represented by <code>xarray.Dataset</code>, an STM is a <code>Dataset</code> object with \"space\" and \"time\" dimension. It can be initiated manually, e.g.:</p> <pre><code># Define dimension sizes\nnspace = 10\nntime = 5\n\n# Initialte STM as Dataset\nstm = xr.Dataset(\n    data_vars=dict(\n        space_time_data=(\n            [\"space\", \"time\"],\n            np.arange(nspace * ntime).reshape((nspace, ntime)),\n        ),\n        space_data=([\"space\"], np.arange(nspace)),\n        time_data=([\"time\"], np.arange(ntime)),\n    ),\n    coords=dict(\n        x_coords=([\"space\"], np.arange(nspace)),\n        y_coords=([\"space\"], np.arange(nspace)),\n        time=([\"time\"], np.arange(ntime)),\n    ),\n)\n\nstm\n</code></pre> <pre><code>&lt;xarray.Dataset&gt;\nDimensions:          (space: 10, time: 5)\nCoordinates:\n    x_coords         (space) int64 0 1 2 3 4 5 6 7 8 9\n    y_coords         (space) int64 0 1 2 3 4 5 6 7 8 9\n  * time             (time) int64 0 1 2 3 4\nDimensions without coordinates: space\nData variables:\n    space_time_data  (space, time) int64 0 1 2 3 4 5 6 ... 43 44 45 46 47 48 49\n    space_data       (space) int64 0 1 2 3 4 5 6 7 8 9\n    time_data        (time) int64 0 1 2 3 4\n</code></pre>"},{"location":"stm_init/#from-a-zarr-storage","title":"From a Zarr storage","text":"<p>If an STM is stored in <code>.zarr</code> format, it can be read by the <code>xarray.open_zarr</code> funtcion:</p> <pre><code>stm = xr.open_zarr('./stm.zarr')\n</code></pre>"},{"location":"stm_init/#from-csv-file","title":"From csv file","text":"<p>STM can also be intiated from a csv file. During this process, the following assumptions are made to the column names of the csv file:</p> <ol> <li>All columns with space-only attributes share the same Regular Expression (RE) pattern in the column names.     E.g. Latitude, Longitude and height columns are named as \"pnt_lat\", \"pnt_lon\" and     \"pnt_height\", sharing the same RE pattern \"^pnt_\";</li> <li>Per space-time attribute, a common RE pattern is shared by all columns. E.g. for the     time-series of amplitude data, the column names are \"amp_20100101\", \"amp_20100110\",     \"amp_20100119\" ..., where \"^amp_\" is the common RE pattern;</li> <li>There is no temporal-only (i.e. 1-row attribute) attribute present in the csv file.</li> </ol> <p>Consider the example csv data. It can be loaded by <code>from_csv</code>:</p> <pre><code>import stmtools\nstm = stmtools.from_csv('example.csv')\n</code></pre> <pre><code>&lt;xarray.Dataset&gt;\nDimensions:                (space: 2500, time: 11)\nCoordinates:\n  * space                  (space) int64 0 1 2 3 4 ... 2495 2496 2497 2498 2499\n  * time                   (time) datetime64[ns] 2016-03-27 ... 2016-07-15\n    lat                    (space) float64 dask.array&lt;chunksize=(2500,), meta=np.ndarray&gt;\n    lon                    (space) float64 dask.array&lt;chunksize=(2500,), meta=np.ndarray&gt;\nData variables: (12/13)\n    pnt_id                 (space) &lt;U1 dask.array&lt;chunksize=(2500,), meta=np.ndarray&gt;\n    pnt_flags              (space) int64 dask.array&lt;chunksize=(2500,), meta=np.ndarray&gt;\n    pnt_line               (space) int64 dask.array&lt;chunksize=(2500,), meta=np.ndarray&gt;\n    pnt_pixel              (space) int64 dask.array&lt;chunksize=(2500,), meta=np.ndarray&gt;\n    pnt_height             (space) float64 dask.array&lt;chunksize=(2500,), meta=np.ndarray&gt;\n    pnt_demheight          (space) float64 dask.array&lt;chunksize=(2500,), meta=np.ndarray&gt;\n    ...                     ...\n    pnt_enscoh             (space) float64 dask.array&lt;chunksize=(2500,), meta=np.ndarray&gt;\n    pnt_ampconsist         (space) float64 dask.array&lt;chunksize=(2500,), meta=np.ndarray&gt;\n    pnt_linear             (space) float64 dask.array&lt;chunksize=(2500,), meta=np.ndarray&gt;\n    deformation            (space, time) float64 dask.array&lt;chunksize=(2500, 11), meta=np.ndarray&gt;\n    amplitude              (space, time) float64 dask.array&lt;chunksize=(2500, 11), meta=np.ndarray&gt;\n    h2ph                   (space, time) float64 dask.array&lt;chunksize=(2500, 11), meta=np.ndarray&gt;\n</code></pre>"},{"location":"stm_init/#by-pixel-selection-from-an-image-stack","title":"By pixel selection from an image stack","text":"<p>An STM can also be generated by selecting pixels from an SLC stack or interferogram stack. An example of the selection is the <code>point_selection</code> implementation of <code>sarxarray</code>.</p>"},{"location":"notebooks/demo_operations_stm/","title":"Example Operations","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\nimport xarray as xr\nimport numpy as np\nimport stmtools\n</pre> from pathlib import Path import xarray as xr import numpy as np import stmtools In\u00a0[2]: Copied! <pre>path_stm = Path('./stm.zarr')\nstmat = xr.open_zarr(path_stm)\nstmat = stmat.chunk({\"space\": 10000, \"time\": -1}) # Chunk 10000 space, no chunk in time\n\nprint(stmat)\n</pre> path_stm = Path('./stm.zarr') stmat = xr.open_zarr(path_stm) stmat = stmat.chunk({\"space\": 10000, \"time\": -1}) # Chunk 10000 space, no chunk in time  print(stmat) <pre>&lt;xarray.Dataset&gt;\nDimensions:    (space: 78582, time: 10)\nCoordinates:\n    azimuth    (space) int64 dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n    lat        (space) float32 dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n    lon        (space) float32 dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n    range      (space) int64 dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n  * time       (time) int64 0 1 2 3 4 5 6 7 8 9\nDimensions without coordinates: space\nData variables:\n    amplitude  (space, time) float32 dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;\n    complex    (space, time) complex64 dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;\n    phase      (space, time) float32 dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;\nAttributes:\n    multi-look:  coarsen-mean\n</pre> In\u00a0[3]: Copied! <pre># Path to the BRP polygon of NL\npath_polygon = Path('bag_light_AMS_WGS84.gpkg')\n</pre> # Path to the BRP polygon of NL path_polygon = Path('bag_light_AMS_WGS84.gpkg') In\u00a0[4]: Copied! <pre>stmat_subset = stmat.stm.subset(method='polygon', polygon=path_polygon)\n\nprint(stmat_subset)\n</pre> stmat_subset = stmat.stm.subset(method='polygon', polygon=path_polygon)  print(stmat_subset) <pre>&lt;xarray.Dataset&gt;\nDimensions:    (space: 26269, time: 10)\nCoordinates:\n    azimuth    (space) int64 dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n    lat        (space) float32 dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n    lon        (space) float32 dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n    range      (space) int64 dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n  * time       (time) int64 0 1 2 3 4 5 6 7 8 9\nDimensions without coordinates: space\nData variables:\n    amplitude  (space, time) float32 dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;\n    complex    (space, time) complex64 dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;\n    phase      (space, time) float32 dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;\nAttributes:\n    multi-look:  coarsen-mean\n</pre> In\u00a0[5]: Copied! <pre>fields_to_query = ['bouwjaar']\n\nstmat_enriched = stmat_subset.stm.enrich_from_polygon(path_polygon, fields_to_query)\n</pre> fields_to_query = ['bouwjaar']  stmat_enriched = stmat_subset.stm.enrich_from_polygon(path_polygon, fields_to_query) <p>The assigined data variable <code>bouwjaar</code> will be an delayed object. We can run <code>compute</code> to peresist the value in memory:</p> In\u00a0[6]: Copied! <pre>year_construction = stmat_enriched['bouwjaar'].compute()\n</pre> year_construction = stmat_enriched['bouwjaar'].compute() In\u00a0[7]: Copied! <pre># Visualize results\nfrom matplotlib import pyplot as plt\nimport matplotlib.cm as cm\n\ncolormap = cm.jet\n\nfig, ax = plt.subplots()\nplt.title(\"Construction year, PS\")\nplt.scatter(stmat_enriched.lon.data, stmat_enriched.lat.data, c=stmat_enriched['bouwjaar'], s=0.004, cmap=colormap)\nplt.clim([1900, 2023])\nplt.colorbar()\n</pre> # Visualize results from matplotlib import pyplot as plt import matplotlib.cm as cm  colormap = cm.jet  fig, ax = plt.subplots() plt.title(\"Construction year, PS\") plt.scatter(stmat_enriched.lon.data, stmat_enriched.lat.data, c=stmat_enriched['bouwjaar'], s=0.004, cmap=colormap) plt.clim([1900, 2023]) plt.colorbar() Out[7]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x7f32383dfa30&gt;</pre>"},{"location":"notebooks/demo_operations_stm/#example-operations","title":"Example Operations\u00b6","text":"<p>In this example notebook, we will demonstrate how to:</p> <ol> <li>Locate the entries in an STM which intersect building polygons;</li> <li>Add year of construction as an attribute to the STM.</li> </ol>"},{"location":"notebooks/demo_operations_stm/#setup","title":"Setup\u00b6","text":""},{"location":"notebooks/demo_operations_stm/#data","title":"Data\u00b6","text":"<p>Data used in this notebook can be downloaded from:</p> <ul> <li>Space-time Matrix in <code>Zarr</code> format: download;</li> <li>Bulding polygons in <code>gpkg</code> format: download.</li> </ul>"},{"location":"notebooks/demo_operations_stm/#environment","title":"Environment\u00b6","text":"<p>For the Python environment setup, we assume you already started an independent Python environment with Python version higher than 3.10.</p> <p>To execute this notebook, install <code>stmtools</code> with the extra option <code>demo</code>:</p> <pre>pip install stmtools[demo]\n</pre> <p>After installation, execute the notebook in a JupyterLab session, which can be started by running the <code>jupyterlab</code> command in your command line:</p> <pre>jupyter-lab\n</pre> <p>A new tab will be opened in your default browser to execute this notebook.</p>"},{"location":"notebooks/demo_operations_stm/#import-dependencies","title":"Import dependencies\u00b6","text":""},{"location":"notebooks/demo_operations_stm/#load-space-time-matrix-from-zarr","title":"Load Space-Time Matrix from Zarr\u00b6","text":"<p>We load the STM stored in Zarr format.</p>"},{"location":"notebooks/demo_operations_stm/#subset-by-polygon","title":"Subset by polygon\u00b6","text":"<p>We select all entries interlects the building polygons: <code>bag_light_AMS_WGS84.gpkg</code>. This takes about 2 minutes.</p>"},{"location":"notebooks/demo_operations_stm/#stm-enrichment-from-polygon-file","title":"STM enrichment from Polygon file\u00b6","text":"<p>The year contstruction information is stored in attribute <code>bouwjaar</code> (Dutch: building year). Let's query it and assign it to the STM.</p>"},{"location":"notebooks/demo_operations_stm/#visualize-the-results","title":"Visualize the results\u00b6","text":""},{"location":"notebooks/demo_order_stm/","title":"Example Ordering","text":"In\u00a0[16]: Copied! <pre>from pathlib import Path\nimport xarray as xr\nimport numpy as np\nimport os\nimport stmtools\n</pre> from pathlib import Path import xarray as xr import numpy as np import os import stmtools In\u00a0[17]: Copied! <pre># Note that normally we would advise using a chuck size closer to 10000.\n# This chunk size is chosen to demonstrate the potential advantages of spatial sorting for larger datasets.\npath_stm = Path('./stm.zarr')\nchunksize = 500\n\npath_stm_ordered = Path(f'./stm_ordered.zarr')\n</pre> # Note that normally we would advise using a chuck size closer to 10000. # This chunk size is chosen to demonstrate the potential advantages of spatial sorting for larger datasets. path_stm = Path('./stm.zarr') chunksize = 500  path_stm_ordered = Path(f'./stm_ordered.zarr') In\u00a0[18]: Copied! <pre># Start a Dask client.\n# Note that this is not necessary when not debugging the Dask operations\n# and that this client can make saving the ordered STM a lot slower.\n# from dask.distributed import Client\n# client = Client()\n</pre> # Start a Dask client. # Note that this is not necessary when not debugging the Dask operations # and that this client can make saving the ordered STM a lot slower. # from dask.distributed import Client # client = Client() In\u00a0[19]: Copied! <pre># Load original Zarr.\nstmat = xr.open_zarr(path_stm)\nstmat = stmat.chunk({'space': 10000, 'time': -1})\nstmat\n</pre> # Load original Zarr. stmat = xr.open_zarr(path_stm) stmat = stmat.chunk({'space': 10000, 'time': -1}) stmat Out[19]: <pre>&lt;xarray.Dataset&gt; Size: 14MB\nDimensions:    (space: 78582, time: 10)\nCoordinates:\n    azimuth    (space) int64 629kB dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n    lat        (space) float32 314kB dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n    lon        (space) float32 314kB dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n    range      (space) int64 629kB dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n  * time       (time) int64 80B 0 1 2 3 4 5 6 7 8 9\nDimensions without coordinates: space\nData variables:\n    amplitude  (space, time) float32 3MB dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;\n    complex    (space, time) complex64 6MB dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;\n    phase      (space, time) float32 3MB dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;\nAttributes:\n    multi-look:  coarsen-mean</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>space: 78582</li><li>time: 10</li></ul></li><li>Coordinates: (5)<ul><li>azimuth(space)int64dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   613.92 kiB   78.12 kiB   Shape   (78582,)   (10000,)   Dask graph   8 chunks in 3 graph layers   Data type   int64 numpy.ndarray  78582 1 </li><li>lat(space)float32dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   306.96 kiB   39.06 kiB   Shape   (78582,)   (10000,)   Dask graph   8 chunks in 3 graph layers   Data type   float32 numpy.ndarray  78582 1 </li><li>lon(space)float32dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   306.96 kiB   39.06 kiB   Shape   (78582,)   (10000,)   Dask graph   8 chunks in 3 graph layers   Data type   float32 numpy.ndarray  78582 1 </li><li>range(space)int64dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   613.92 kiB   78.12 kiB   Shape   (78582,)   (10000,)   Dask graph   8 chunks in 3 graph layers   Data type   int64 numpy.ndarray  78582 1 </li><li>time(time)int640 1 2 3 4 5 6 7 8 9<pre>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</pre></li></ul></li><li>Data variables: (3)<ul><li>amplitude(space, time)float32dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   3.00 MiB   390.62 kiB   Shape   (78582, 10)   (10000, 10)   Dask graph   8 chunks in 3 graph layers   Data type   float32 numpy.ndarray  10 78582 </li><li>complex(space, time)complex64dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   6.00 MiB   781.25 kiB   Shape   (78582, 10)   (10000, 10)   Dask graph   8 chunks in 3 graph layers   Data type   complex64 numpy.ndarray  10 78582 </li><li>phase(space, time)float32dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   3.00 MiB   390.62 kiB   Shape   (78582, 10)   (10000, 10)   Dask graph   8 chunks in 3 graph layers   Data type   float32 numpy.ndarray  10 78582 </li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64', name='time'))</pre></li></ul></li><li>Attributes: (1)multi-look :coarsen-mean</li></ul> In\u00a0[20]: Copied! <pre>if not os.path.isdir(path_stm_ordered):\n    # Reorder a copy of the STM.\n    print(\"ordering...\")\n    stmat_ordered = stmat.copy()\n    stmat_ordered = stmat_ordered.stm.reorder(xlabel=\"azimuth\", ylabel=\"range\")\n    \n    # Save to Zarr.\n    # effect of encoding: https://github.com/pydata/xarray/issues/7686\n    stmat_ordered = stmat_ordered.reset_encoding()\n    stmat_ordered.to_zarr(path_stm_ordered, mode='w')\n\n# Load ordered Zarr.\nstmat_ordered = xr.open_zarr(path_stm_ordered)\nstmat_ordered\n</pre> if not os.path.isdir(path_stm_ordered):     # Reorder a copy of the STM.     print(\"ordering...\")     stmat_ordered = stmat.copy()     stmat_ordered = stmat_ordered.stm.reorder(xlabel=\"azimuth\", ylabel=\"range\")          # Save to Zarr.     # effect of encoding: https://github.com/pydata/xarray/issues/7686     stmat_ordered = stmat_ordered.reset_encoding()     stmat_ordered.to_zarr(path_stm_ordered, mode='w')  # Load ordered Zarr. stmat_ordered = xr.open_zarr(path_stm_ordered) stmat_ordered Out[20]: <pre>&lt;xarray.Dataset&gt; Size: 15MB\nDimensions:    (space: 78582, time: 10)\nCoordinates:\n    azimuth    (space) int64 629kB dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n    lat        (space) float32 314kB dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n    lon        (space) float32 314kB dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n    range      (space) int64 629kB dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n  * time       (time) int64 80B 0 1 2 3 4 5 6 7 8 9\nDimensions without coordinates: space\nData variables:\n    amplitude  (space, time) float32 3MB dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;\n    complex    (space, time) complex64 6MB dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;\n    order      (space) int64 629kB dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;\n    phase      (space, time) float32 3MB dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;\nAttributes:\n    multi-look:  coarsen-mean</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>space: 78582</li><li>time: 10</li></ul></li><li>Coordinates: (5)<ul><li>azimuth(space)int64dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   613.92 kiB   78.12 kiB   Shape   (78582,)   (10000,)   Dask graph   8 chunks in 2 graph layers   Data type   int64 numpy.ndarray  78582 1 </li><li>lat(space)float32dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   306.96 kiB   39.06 kiB   Shape   (78582,)   (10000,)   Dask graph   8 chunks in 2 graph layers   Data type   float32 numpy.ndarray  78582 1 </li><li>lon(space)float32dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   306.96 kiB   39.06 kiB   Shape   (78582,)   (10000,)   Dask graph   8 chunks in 2 graph layers   Data type   float32 numpy.ndarray  78582 1 </li><li>range(space)int64dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   613.92 kiB   78.12 kiB   Shape   (78582,)   (10000,)   Dask graph   8 chunks in 2 graph layers   Data type   int64 numpy.ndarray  78582 1 </li><li>time(time)int640 1 2 3 4 5 6 7 8 9<pre>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</pre></li></ul></li><li>Data variables: (4)<ul><li>amplitude(space, time)float32dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   3.00 MiB   390.62 kiB   Shape   (78582, 10)   (10000, 10)   Dask graph   8 chunks in 2 graph layers   Data type   float32 numpy.ndarray  10 78582 </li><li>complex(space, time)complex64dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   6.00 MiB   781.25 kiB   Shape   (78582, 10)   (10000, 10)   Dask graph   8 chunks in 2 graph layers   Data type   complex64 numpy.ndarray  10 78582 </li><li>order(space)int64dask.array&lt;chunksize=(10000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   613.92 kiB   78.12 kiB   Shape   (78582,)   (10000,)   Dask graph   8 chunks in 2 graph layers   Data type   int64 numpy.ndarray  78582 1 </li><li>phase(space, time)float32dask.array&lt;chunksize=(10000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   3.00 MiB   390.62 kiB   Shape   (78582, 10)   (10000, 10)   Dask graph   8 chunks in 2 graph layers   Data type   float32 numpy.ndarray  10 78582 </li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64', name='time'))</pre></li></ul></li><li>Attributes: (1)multi-look :coarsen-mean</li></ul> In\u00a0[21]: Copied! <pre># Make STM with smaller chunks.\nstmat_chunked = stmat.copy().chunk({'space': chunksize, 'time': -1})\nstmat_chunked = stmat_chunked.isel(space=slice(24000, 48000))\nstmat_chunked\n</pre> # Make STM with smaller chunks. stmat_chunked = stmat.copy().chunk({'space': chunksize, 'time': -1}) stmat_chunked = stmat_chunked.isel(space=slice(24000, 48000)) stmat_chunked Out[21]: <pre>&lt;xarray.Dataset&gt; Size: 4MB\nDimensions:    (space: 24000, time: 10)\nCoordinates:\n    azimuth    (space) int64 192kB dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;\n    lat        (space) float32 96kB dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;\n    lon        (space) float32 96kB dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;\n    range      (space) int64 192kB dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;\n  * time       (time) int64 80B 0 1 2 3 4 5 6 7 8 9\nDimensions without coordinates: space\nData variables:\n    amplitude  (space, time) float32 960kB dask.array&lt;chunksize=(500, 10), meta=np.ndarray&gt;\n    complex    (space, time) complex64 2MB dask.array&lt;chunksize=(500, 10), meta=np.ndarray&gt;\n    phase      (space, time) float32 960kB dask.array&lt;chunksize=(500, 10), meta=np.ndarray&gt;\nAttributes:\n    multi-look:  coarsen-mean</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>space: 24000</li><li>time: 10</li></ul></li><li>Coordinates: (5)<ul><li>azimuth(space)int64dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;  Array   Chunk   Bytes   187.50 kiB   3.91 kiB   Shape   (24000,)   (500,)   Dask graph   48 chunks in 5 graph layers   Data type   int64 numpy.ndarray  24000 1 </li><li>lat(space)float32dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;  Array   Chunk   Bytes   93.75 kiB   1.95 kiB   Shape   (24000,)   (500,)   Dask graph   48 chunks in 5 graph layers   Data type   float32 numpy.ndarray  24000 1 </li><li>lon(space)float32dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;  Array   Chunk   Bytes   93.75 kiB   1.95 kiB   Shape   (24000,)   (500,)   Dask graph   48 chunks in 5 graph layers   Data type   float32 numpy.ndarray  24000 1 </li><li>range(space)int64dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;  Array   Chunk   Bytes   187.50 kiB   3.91 kiB   Shape   (24000,)   (500,)   Dask graph   48 chunks in 5 graph layers   Data type   int64 numpy.ndarray  24000 1 </li><li>time(time)int640 1 2 3 4 5 6 7 8 9<pre>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</pre></li></ul></li><li>Data variables: (3)<ul><li>amplitude(space, time)float32dask.array&lt;chunksize=(500, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   0.92 MiB   19.53 kiB   Shape   (24000, 10)   (500, 10)   Dask graph   48 chunks in 5 graph layers   Data type   float32 numpy.ndarray  10 24000 </li><li>complex(space, time)complex64dask.array&lt;chunksize=(500, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   1.83 MiB   39.06 kiB   Shape   (24000, 10)   (500, 10)   Dask graph   48 chunks in 5 graph layers   Data type   complex64 numpy.ndarray  10 24000 </li><li>phase(space, time)float32dask.array&lt;chunksize=(500, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   0.92 MiB   19.53 kiB   Shape   (24000, 10)   (500, 10)   Dask graph   48 chunks in 5 graph layers   Data type   float32 numpy.ndarray  10 24000 </li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64', name='time'))</pre></li></ul></li><li>Attributes: (1)multi-look :coarsen-mean</li></ul> In\u00a0[22]: Copied! <pre># Make ordered STM with smaller chunks.\nstmat_ordered_chunked = stmat_ordered.copy().chunk({'space': chunksize, 'time': -1})\nstmat_ordered_chunked = stmat_ordered_chunked.isel(space=slice(24000, 48000))\nstmat_ordered_chunked\n</pre> # Make ordered STM with smaller chunks. stmat_ordered_chunked = stmat_ordered.copy().chunk({'space': chunksize, 'time': -1}) stmat_ordered_chunked = stmat_ordered_chunked.isel(space=slice(24000, 48000)) stmat_ordered_chunked Out[22]: <pre>&lt;xarray.Dataset&gt; Size: 5MB\nDimensions:    (space: 24000, time: 10)\nCoordinates:\n    azimuth    (space) int64 192kB dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;\n    lat        (space) float32 96kB dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;\n    lon        (space) float32 96kB dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;\n    range      (space) int64 192kB dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;\n  * time       (time) int64 80B 0 1 2 3 4 5 6 7 8 9\nDimensions without coordinates: space\nData variables:\n    amplitude  (space, time) float32 960kB dask.array&lt;chunksize=(500, 10), meta=np.ndarray&gt;\n    complex    (space, time) complex64 2MB dask.array&lt;chunksize=(500, 10), meta=np.ndarray&gt;\n    order      (space) int64 192kB dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;\n    phase      (space, time) float32 960kB dask.array&lt;chunksize=(500, 10), meta=np.ndarray&gt;\nAttributes:\n    multi-look:  coarsen-mean</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>space: 24000</li><li>time: 10</li></ul></li><li>Coordinates: (5)<ul><li>azimuth(space)int64dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;  Array   Chunk   Bytes   187.50 kiB   3.91 kiB   Shape   (24000,)   (500,)   Dask graph   48 chunks in 4 graph layers   Data type   int64 numpy.ndarray  24000 1 </li><li>lat(space)float32dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;  Array   Chunk   Bytes   93.75 kiB   1.95 kiB   Shape   (24000,)   (500,)   Dask graph   48 chunks in 4 graph layers   Data type   float32 numpy.ndarray  24000 1 </li><li>lon(space)float32dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;  Array   Chunk   Bytes   93.75 kiB   1.95 kiB   Shape   (24000,)   (500,)   Dask graph   48 chunks in 4 graph layers   Data type   float32 numpy.ndarray  24000 1 </li><li>range(space)int64dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;  Array   Chunk   Bytes   187.50 kiB   3.91 kiB   Shape   (24000,)   (500,)   Dask graph   48 chunks in 4 graph layers   Data type   int64 numpy.ndarray  24000 1 </li><li>time(time)int640 1 2 3 4 5 6 7 8 9<pre>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</pre></li></ul></li><li>Data variables: (4)<ul><li>amplitude(space, time)float32dask.array&lt;chunksize=(500, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   0.92 MiB   19.53 kiB   Shape   (24000, 10)   (500, 10)   Dask graph   48 chunks in 4 graph layers   Data type   float32 numpy.ndarray  10 24000 </li><li>complex(space, time)complex64dask.array&lt;chunksize=(500, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   1.83 MiB   39.06 kiB   Shape   (24000, 10)   (500, 10)   Dask graph   48 chunks in 4 graph layers   Data type   complex64 numpy.ndarray  10 24000 </li><li>order(space)int64dask.array&lt;chunksize=(500,), meta=np.ndarray&gt;  Array   Chunk   Bytes   187.50 kiB   3.91 kiB   Shape   (24000,)   (500,)   Dask graph   48 chunks in 4 graph layers   Data type   int64 numpy.ndarray  24000 1 </li><li>phase(space, time)float32dask.array&lt;chunksize=(500, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   0.92 MiB   19.53 kiB   Shape   (24000, 10)   (500, 10)   Dask graph   48 chunks in 4 graph layers   Data type   float32 numpy.ndarray  10 24000 </li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64', name='time'))</pre></li></ul></li><li>Attributes: (1)multi-look :coarsen-mean</li></ul> In\u00a0[23]: Copied! <pre>from matplotlib import pyplot as plt\nimport matplotlib.cm as cm\n</pre> from matplotlib import pyplot as plt import matplotlib.cm as cm In\u00a0[24]: Copied! <pre>def plot_stmats(stmat_0, stmat_1):\n    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n    colors = cm.rainbow(np.linspace(0, 1, len(stmat_0.chunks[\"space\"])))\n    \n    start_idx = 0\n    for color, chunk in zip(colors, stmat_0.chunks[\"space\"]):\n        space = slice(start_idx, start_idx+chunk)\n        scatter_0 = stmat_0.isel(space=space)\n        scatter_1 = stmat_1.isel(space=space)\n        axs[0].scatter(scatter_0['lon'], scatter_0['lat'], s=1, color=color)\n        axs[1].scatter(scatter_1['lon'], scatter_1['lat'], s=1, color=color)\n        start_idx += chunk\n</pre> def plot_stmats(stmat_0, stmat_1):     fig, axs = plt.subplots(1, 2, figsize=(10, 5))     colors = cm.rainbow(np.linspace(0, 1, len(stmat_0.chunks[\"space\"])))          start_idx = 0     for color, chunk in zip(colors, stmat_0.chunks[\"space\"]):         space = slice(start_idx, start_idx+chunk)         scatter_0 = stmat_0.isel(space=space)         scatter_1 = stmat_1.isel(space=space)         axs[0].scatter(scatter_0['lon'], scatter_0['lat'], s=1, color=color)         axs[1].scatter(scatter_1['lon'], scatter_1['lat'], s=1, color=color)         start_idx += chunk In\u00a0[25]: Copied! <pre># Visualize big chunks before and after reordering.\nplot_stmats(stmat, stmat_ordered)\n</pre> # Visualize big chunks before and after reordering. plot_stmats(stmat, stmat_ordered) In\u00a0[26]: Copied! <pre># Visualize small chunks before and after reordering.\nplot_stmats(stmat_chunked, stmat_ordered_chunked)\n</pre> # Visualize small chunks before and after reordering. plot_stmats(stmat_chunked, stmat_ordered_chunked) In\u00a0[27]: Copied! <pre>path_polygon = Path('bag_light_AMS_WGS84.gpkg')\n</pre> path_polygon = Path('bag_light_AMS_WGS84.gpkg') In\u00a0[28]: Copied! <pre># Time the reordering operation.\ntime_ordering = %timeit -o stmat.copy().stm.reorder(xlabel=\"azimuth\", ylabel=\"range\")\ntime_ordering\n</pre> # Time the reordering operation. time_ordering = %timeit -o stmat.copy().stm.reorder(xlabel=\"azimuth\", ylabel=\"range\") time_ordering <pre>/storage/miniforge3/envs/mbl_stmtools/lib/python3.12/site-packages/xarray/core/indexing.py:1620: PerformanceWarning: Slicing with an out-of-order index is generating 230 times more chunks\n  return self.array[key]\n/storage/miniforge3/envs/mbl_stmtools/lib/python3.12/site-packages/xarray/core/indexing.py:1620: PerformanceWarning: Slicing with an out-of-order index is generating 230 times more chunks\n  return self.array[key]\n/storage/miniforge3/envs/mbl_stmtools/lib/python3.12/site-packages/xarray/core/indexing.py:1620: PerformanceWarning: Slicing with an out-of-order index is generating 230 times more chunks\n  return self.array[key]\n/storage/miniforge3/envs/mbl_stmtools/lib/python3.12/site-packages/xarray/core/indexing.py:1620: PerformanceWarning: Slicing with an out-of-order index is generating 230 times more chunks\n  return self.array[key]\n/storage/miniforge3/envs/mbl_stmtools/lib/python3.12/site-packages/xarray/core/indexing.py:1620: PerformanceWarning: Slicing with an out-of-order index is generating 230 times more chunks\n  return self.array[key]\n/storage/miniforge3/envs/mbl_stmtools/lib/python3.12/site-packages/xarray/core/indexing.py:1620: PerformanceWarning: Slicing with an out-of-order index is generating 230 times more chunks\n  return self.array[key]\n/storage/miniforge3/envs/mbl_stmtools/lib/python3.12/site-packages/xarray/core/indexing.py:1620: PerformanceWarning: Slicing with an out-of-order index is generating 230 times more chunks\n  return self.array[key]\n/storage/miniforge3/envs/mbl_stmtools/lib/python3.12/site-packages/xarray/core/indexing.py:1620: PerformanceWarning: Slicing with an out-of-order index is generating 230 times more chunks\n  return self.array[key]\n</pre> <pre>875 ms \u00b1 64.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n</pre> Out[28]: <pre>&lt;TimeitResult : 875 ms \u00b1 64.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)&gt;</pre> In\u00a0[29]: Copied! <pre>%%timeit -o\n# Time subset operation on original STM.\nstmat_subset = stmat.stm.subset(method='polygon', polygon=path_polygon)\nphase = stmat_subset['phase'].compute()\n</pre> %%timeit -o # Time subset operation on original STM. stmat_subset = stmat.stm.subset(method='polygon', polygon=path_polygon) phase = stmat_subset['phase'].compute() <pre>1min 45s \u00b1 452 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n</pre> Out[29]: <pre>&lt;TimeitResult : 1min 45s \u00b1 452 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)&gt;</pre> In\u00a0[30]: Copied! <pre>time_subset = _\ntime_subset\n</pre> time_subset = _ time_subset Out[30]: <pre>&lt;TimeitResult : 1min 45s \u00b1 452 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)&gt;</pre> In\u00a0[31]: Copied! <pre>%%timeit -o\n# Time subset operation on ordered STM.\nstmat_ordered_subset = stmat_ordered.stm.subset(method='polygon', polygon=path_polygon)\nphase = stmat_ordered_subset['phase'].compute()\n</pre> %%timeit -o # Time subset operation on ordered STM. stmat_ordered_subset = stmat_ordered.stm.subset(method='polygon', polygon=path_polygon) phase = stmat_ordered_subset['phase'].compute() <pre>4min 14s \u00b1 401 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n</pre> Out[31]: <pre>&lt;TimeitResult : 4min 14s \u00b1 401 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)&gt;</pre> In\u00a0[32]: Copied! <pre>time_subset_ordered = _\ntime_subset_ordered\n</pre> time_subset_ordered = _ time_subset_ordered Out[32]: <pre>&lt;TimeitResult : 4min 14s \u00b1 401 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)&gt;</pre> In\u00a0[33]: Copied! <pre>%%timeit -o\n# Time subset operation on chunked STM.\nstmat_chunked_subset = stmat_chunked.stm.subset(method='polygon', polygon=path_polygon)\nphase = stmat_chunked_subset['phase'].compute()\n</pre> %%timeit -o # Time subset operation on chunked STM. stmat_chunked_subset = stmat_chunked.stm.subset(method='polygon', polygon=path_polygon) phase = stmat_chunked_subset['phase'].compute() <pre>6min 55s \u00b1 1min 11s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n</pre> Out[33]: <pre>&lt;TimeitResult : 6min 55s \u00b1 1min 11s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)&gt;</pre> In\u00a0[34]: Copied! <pre>time_subset_chunked = _\ntime_subset_chunked\n</pre> time_subset_chunked = _ time_subset_chunked Out[34]: <pre>&lt;TimeitResult : 6min 55s \u00b1 1min 11s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)&gt;</pre> In\u00a0[35]: Copied! <pre>%%timeit -o\n# Time subset operation on ordered chunked STM.\nstmat_ordered_chunked_subset = stmat_ordered_chunked.stm.subset(method='polygon', polygon=path_polygon)\nphase = stmat_ordered_chunked_subset['phase'].compute()\n</pre> %%timeit -o # Time subset operation on ordered chunked STM. stmat_ordered_chunked_subset = stmat_ordered_chunked.stm.subset(method='polygon', polygon=path_polygon) phase = stmat_ordered_chunked_subset['phase'].compute() <pre>2min 8s \u00b1 330 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n</pre> Out[35]: <pre>&lt;TimeitResult : 2min 8s \u00b1 330 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)&gt;</pre> In\u00a0[36]: Copied! <pre>stmat_ordered_chunked_chunked = _\nstmat_ordered_chunked_chunked\n</pre> stmat_ordered_chunked_chunked = _ stmat_ordered_chunked_chunked Out[36]: <pre>&lt;TimeitResult : 2min 8s \u00b1 330 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)&gt;</pre> In\u00a0[37]: Copied! <pre>print(f\"Ordering:                  {time_ordering}\")\nprint(f\"Subset (original):         {time_subset}\")\nprint(f\"Subset (ordered):          {time_subset_ordered}\")\nprint(\"\")\nprint(f\"Subset (chunked):          {time_subset_chunked}\")\nprint(f\"Subset (chunked, ordered): {stmat_ordered_chunked_chunked}\")\n</pre> print(f\"Ordering:                  {time_ordering}\") print(f\"Subset (original):         {time_subset}\") print(f\"Subset (ordered):          {time_subset_ordered}\") print(\"\") print(f\"Subset (chunked):          {time_subset_chunked}\") print(f\"Subset (chunked, ordered): {stmat_ordered_chunked_chunked}\") <pre>Ordering:                  875 ms \u00b1 64.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\nSubset (original):         1min 45s \u00b1 452 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\nSubset (ordered):          4min 14s \u00b1 401 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nSubset (chunked):          6min 55s \u00b1 1min 11s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\nSubset (chunked, ordered): 2min 8s \u00b1 330 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n</pre>"},{"location":"notebooks/demo_order_stm/#example-ordering","title":"Example Ordering\u00b6","text":"<p>In this example notebook, we will compare the performance of the operations of the Example Operations notebook with and without spatial ordering.</p> <p>We will first load the example STM, order it according to the Morton code of the pixel coordinates and store and reload it. This will provide a fair comparison of delayed operations.</p> <p>For many operations, spatial ordering becomes beneficial when the chuck size is small relative to the data size. We will simulate this by creating duplicate STMs with a chunk size that is a lot smaller than normally recommended.</p> <p>We will then show the change in the order of the elements by plotting how they are chunked. We provide two examples:</p> <ol> <li>The chunks are large relative to the complete dataset. Several of the ordered chunks cover a large part of the spatial extent.</li> <li>The chunks are small relative to the complete dataset. These ordered chunks are much more spatially coherent than the original chunks.</li> </ol> <p>Note that in the first example, reordering will likely not improve operation efficiency.</p> <p>Finally, we will apply the subset operations of the Example Operations notebook on each dataset and compare their processing times.</p>"},{"location":"notebooks/demo_order_stm/#prepare-the-data","title":"Prepare the data\u00b6","text":"<p>For setup and, see Example Operations notebook</p> <p>To preform a fair comparison with re-chunked and ordered datasets, we will store and reload the data after re-chunking and ordering.</p>"},{"location":"notebooks/demo_order_stm/#visualize-the-results","title":"Visualize the results\u00b6","text":"<p>The images below are colored by chunk.</p>"},{"location":"notebooks/demo_order_stm/#apply-subset-operation","title":"Apply subset operation\u00b6","text":"<p>These operations are applied to both the original STMs and the ordered STMs and timed.</p> <p>Note that the profiling can take some time.</p>"}]}